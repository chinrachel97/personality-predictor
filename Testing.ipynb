{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-defined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify filenames and directories here\n",
    "# Specify the directory containing user tweets .json + .gz files\n",
    "TWEETS_DIRECTORY = \"./users-new/\"\n",
    "\n",
    "# Specify the name of the CSV file containing personality scores for each user\n",
    "TRAIN_LABEL_FILE = \"./valid_uids.csv\"\n",
    "\n",
    "# Specify how many of each file type to include in the details section when searching for files\n",
    "# A value of 10 would mean up to 10 failures AND 10 successes are reported, they are separate.\n",
    "MAX_FILES_LISTED_PER_TYPE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['./vectorized/', './filtered/', './users-new/', './prediction/']\n",
    "files = ['./svm.model', './random_forest.model']\n",
    "\n",
    "uids = []\n",
    "for uid in pd.read_csv(TRAIN_LABEL_FILE):\n",
    "    uids.append(int(Decimal(uid)))\n",
    "\n",
    "# a list of files related to tweets, as pairs of the format [list of files, notes for display]\n",
    "tweetLists = [[[TWEETS_DIRECTORY + str(uid) + '.json.gz' for uid in uids], 'Scraped Tweets'],\n",
    "              [[TWEETS_DIRECTORY + str(uid) + '.json.gz.json' for uid in uids], 'Metadata about scraping'],\n",
    "              [[\"./vectorized/\" + str(uid) + '.csv' for uid in uids], 'Vectorized tweets'],\n",
    "              [[\"./filtered/\" + str(uid) + '.csv' for uid in uids], 'Filtering tweets'],\n",
    "              [[\"./prediction/\" + str(uid) + '.csv' for uid in uids], 'Personality predictions']\n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Not recording additional failures for Scraped Tweets. Too many missing files.\n",
      "Warning: Not recording additional failures for Metadata about scraping. Too many missing files.\n",
      "Warning: Not recording additional failures for Vectorized tweets. Too many missing files.\n",
      "Warning: Not recording additional failures for Filtering tweets. Too many missing files.\n",
      "Warning: Not recording additional failures for Personality predictions. Too many missing files.\n"
     ]
    }
   ],
   "source": [
    "results = [[\"<b>File Name</b>\", \"<b>Exists</b>\", \"<b>Notes</b>\"]]\n",
    "\n",
    "fileStatTable = [[\"<b>File Type</b>\", \"<b># Found</b>\", \"<b># Missing</b>\"]]\n",
    "\n",
    "statListDir = ['Directory', 0, 0]\n",
    "for d in directories:\n",
    "    exists = os.path.exists(d)\n",
    "    if exists:\n",
    "        statListDir[1] += 1\n",
    "    else:\n",
    "        statListDir[2] += 1\n",
    "    results.append([d, exists, 'Directory'])\n",
    "fileStatTable.append(statListDir)\n",
    "\n",
    "statListFile = ['Misc. File', 0, 0]\n",
    "for f in files:\n",
    "    exists = os.path.isfile(d)\n",
    "    if exists:\n",
    "        statListFile[1] += 1\n",
    "    else:\n",
    "        statListFile[2] += 1\n",
    "    results.append([f, exists, 'Misc. File'])\n",
    "fileStatTable.append(statListFile)\n",
    "\n",
    "for listPair in tweetLists:\n",
    "    numMissing = 0\n",
    "    numFound = 0\n",
    "    printedErrorM = False\n",
    "    printedErrorF = False\n",
    "    for expectedFile in listPair[0]:\n",
    "        exists = os.path.exists(expectedFile)\n",
    "        if exists:\n",
    "            numFound += 1\n",
    "            if numFound >= MAX_FILES_LISTED_PER_TYPE:\n",
    "                if not printedErrorF:\n",
    "                    print('Warning: Not recording additional successes for ' + listPair[1] + ' for brevity.')\n",
    "                    printedErrorF = True\n",
    "                continue\n",
    "        else:\n",
    "            numMissing += 1\n",
    "            if numMissing >= MAX_FILES_LISTED_PER_TYPE:\n",
    "                if not printedErrorM:\n",
    "                    print('Warning: Not recording additional failures for ' + listPair[1] + '. Too many missing files.')\n",
    "                    printedErrorM = True\n",
    "                continue\n",
    "        results.append([expectedFile, exists, listPair[1]])\n",
    "    fileStatTable.append([listPair[1], numFound, numMissing])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in results:\n",
    "    if row[1] == True:\n",
    "        row[1] = '<font color=\"green\">Yes</font>'\n",
    "    elif row[1] == False:\n",
    "        row[1] = '<font color=\"red\">No</font>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Symmary:</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><b>File Type</b></td><td><b># Found</b></td><td><b># Missing</b></td></tr><tr><td>Directory</td><td>1</td><td>3</td></tr><tr><td>Misc. File</td><td>0</td><td>2</td></tr><tr><td>Scraped Tweets</td><td>3</td><td>30427</td></tr><tr><td>Metadata about scraping</td><td>4</td><td>30426</td></tr><tr><td>Vectorized tweets</td><td>0</td><td>30430</td></tr><tr><td>Filtering tweets</td><td>0</td><td>30430</td></tr><tr><td>Personality predictions</td><td>0</td><td>30430</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Details:</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><b>File Name</b></td><td><b>Exists</b></td><td><b>Notes</b></td></tr><tr><td>./vectorized/</td><td><font color=\"red\">No</font></td><td>Directory</td></tr><tr><td>./filtered/</td><td><font color=\"red\">No</font></td><td>Directory</td></tr><tr><td>./users-new/</td><td><font color=\"green\">Yes</font></td><td>Directory</td></tr><tr><td>./prediction/</td><td><font color=\"red\">No</font></td><td>Directory</td></tr><tr><td>./svm.model</td><td><font color=\"red\">No</font></td><td>Misc. File</td></tr><tr><td>./random_forest.model</td><td><font color=\"red\">No</font></td><td>Misc. File</td></tr><tr><td>./users-new/12432922.json.gz</td><td><font color=\"red\">No</font></td><td>Scraped Tweets</td></tr><tr><td>./users-new/172018245.json.gz</td><td><font color=\"red\">No</font></td><td>Scraped Tweets</td></tr><tr><td>./users-new/929862361.json.gz</td><td><font color=\"red\">No</font></td><td>Scraped Tweets</td></tr><tr><td>./users-new/16565806.json.gz</td><td><font color=\"red\">No</font></td><td>Scraped Tweets</td></tr><tr><td>./users-new/38381682.json.gz</td><td><font color=\"green\">Yes</font></td><td>Scraped Tweets</td></tr><tr><td>./users-new/36670025.json.gz</td><td><font color=\"green\">Yes</font></td><td>Scraped Tweets</td></tr><tr><td>./users-new/36863478.json.gz</td><td><font color=\"green\">Yes</font></td><td>Scraped Tweets</td></tr><tr><td>./users-new/12432922.json.gz.json</td><td><font color=\"red\">No</font></td><td>Metadata about scraping</td></tr><tr><td>./users-new/172018245.json.gz.json</td><td><font color=\"red\">No</font></td><td>Metadata about scraping</td></tr><tr><td>./users-new/929862361.json.gz.json</td><td><font color=\"red\">No</font></td><td>Metadata about scraping</td></tr><tr><td>./users-new/16565806.json.gz.json</td><td><font color=\"red\">No</font></td><td>Metadata about scraping</td></tr><tr><td>./users-new/38381682.json.gz.json</td><td><font color=\"green\">Yes</font></td><td>Metadata about scraping</td></tr><tr><td>./users-new/36670025.json.gz.json</td><td><font color=\"green\">Yes</font></td><td>Metadata about scraping</td></tr><tr><td>./users-new/36863478.json.gz.json</td><td><font color=\"green\">Yes</font></td><td>Metadata about scraping</td></tr><tr><td>./users-new/41056423.json.gz.json</td><td><font color=\"green\">Yes</font></td><td>Metadata about scraping</td></tr><tr><td>./vectorized/12432922.csv</td><td><font color=\"red\">No</font></td><td>Vectorized tweets</td></tr><tr><td>./vectorized/172018245.csv</td><td><font color=\"red\">No</font></td><td>Vectorized tweets</td></tr><tr><td>./vectorized/929862361.csv</td><td><font color=\"red\">No</font></td><td>Vectorized tweets</td></tr><tr><td>./vectorized/16565806.csv</td><td><font color=\"red\">No</font></td><td>Vectorized tweets</td></tr><tr><td>./filtered/12432922.csv</td><td><font color=\"red\">No</font></td><td>Filtering tweets</td></tr><tr><td>./filtered/172018245.csv</td><td><font color=\"red\">No</font></td><td>Filtering tweets</td></tr><tr><td>./filtered/929862361.csv</td><td><font color=\"red\">No</font></td><td>Filtering tweets</td></tr><tr><td>./filtered/16565806.csv</td><td><font color=\"red\">No</font></td><td>Filtering tweets</td></tr><tr><td>./prediction/12432922.csv</td><td><font color=\"red\">No</font></td><td>Personality predictions</td></tr><tr><td>./prediction/172018245.csv</td><td><font color=\"red\">No</font></td><td>Personality predictions</td></tr><tr><td>./prediction/929862361.csv</td><td><font color=\"red\">No</font></td><td>Personality predictions</td></tr><tr><td>./prediction/16565806.csv</td><td><font color=\"red\">No</font></td><td>Personality predictions</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<h2>Symmary:</h2>'))\n",
    "\n",
    "display(HTML(\n",
    "   '<table><tr>{}</tr></table>'.format(\n",
    "       '</tr><tr>'.join(\n",
    "           '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in fileStatTable)\n",
    "       )\n",
    "))\n",
    "\n",
    "display(HTML('<h2>Details:</h2>'))\n",
    "\n",
    "display(HTML(\n",
    "   '<table><tr>{}</tr></table>'.format(\n",
    "       '</tr><tr>'.join(\n",
    "           '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in results)\n",
    "       )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
