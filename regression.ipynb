{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updates\n",
    "#### (3/26/19)\n",
    "- Separated urls into links and linked pictures\n",
    "- Changed racist word count to regular frequency\n",
    "- Racist/neutral scores are aggregated\n",
    "- Time tweet created feature removed\n",
    "- Corrected a few data types in the user-feature dataframe\n",
    "- Replaced regular variables with np.arrays when calculating metrics to shorten script\n",
    "- Specify racism dictionary path in cell under \"User-defined Variables\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### User-defined Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Specify filenames and directories here\n",
    "# Specify the directory containing user tweets .json + .gz files\n",
    "TWEETS_DIRECTORY = \"../users-new/\"\n",
    "\n",
    "# Specify the name of the CSV file containing personality scores for each user\n",
    "TRAIN_LABEL_FILE = \"../train_labels_rand.csv\"\n",
    "\n",
    "# Specify the name of the CSV file containing dictionary words related to racism\n",
    "RACISM_DICT_FILE = \"../expanded.csv\"\n",
    "\n",
    "# Specify the name of the CSV file containing dictionary words related to religiosity\n",
    "RELIGIOUS_DICTIONARY = \"../religious_corpus.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program Begins Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Imports here\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from textstat.textstat import textstatistics, easy_word_set, legacy_round\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from dictfeaturizer import DictFeaturizer\n",
    "from nltk import TweetTokenizer\n",
    "from textstat.textstat import textstat\n",
    "import graphviz\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk.data\n",
    "import emoji\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Function definitions for accessing/parsing twitter/training data\n",
    "# Get tweets from one user\n",
    "def getUserTweetsAndData(userTweetsFile):\n",
    "    data = []\n",
    "    tweets = []\n",
    "\n",
    "    with gzip.open(userTweetsFile,'r') as f:        \n",
    "        for tweetDeetsBinary in f:\n",
    "            # Convert each line (binary) to string\n",
    "            tweetDeetsStr = tweetDeetsBinary.decode('utf-8')\n",
    "\n",
    "            # Generate json objects\n",
    "            tweetDeetsJson = json.loads(tweetDeetsStr)\n",
    "            data.append(tweetDeetsJson)            \n",
    "            tweets.append(tweetDeetsJson[\"text\"])\n",
    "    \n",
    "    return data, tweets\n",
    "\n",
    "# Get a user's ID\n",
    "def getUserID(TWEETS_DIRECTORY, userTweetsFile):\n",
    "    pattern = \"(\" + TWEETS_DIRECTORY.replace(\"/\", \"\\/\") + \")(\\d+)(\\.json\\.gz)\"\n",
    "    m = re.match(pattern, userTweetsFile)\n",
    "    \n",
    "    return str(m[2])\n",
    "\n",
    "# Get a user's SDO and RWA scores\n",
    "def getUserScores(TWEETS_DIRECTORY, userTweetsFile, df):\n",
    "    userID = getUserID(TWEETS_DIRECTORY, userTweetsFile)\n",
    "    sdo_score = float(df.loc[userID, \"sdo\"])\n",
    "    rwa_score = float(df.loc[userID, \"rwa\"])\n",
    "    \n",
    "    return sdo_score, rwa_score\n",
    "\n",
    "# Print a user's data\n",
    "def printUserStats(TWEETS_DIRECTORY, userTweetsFile, df):\n",
    "    # Get user personality scores\n",
    "    personalityScores = getUserScores(TWEETS_DIRECTORY, userTweetsFile, df)\n",
    "    sdo_score = personalityScores[0]\n",
    "    rwa_score = personalityScores[1]\n",
    "    \n",
    "    # Print user data\n",
    "    print(\"Current twitter user file:\", userTweetsFile)\n",
    "    print(\"Number of tweets:\", int(df.loc[userID, \"num_tweets\"]))\n",
    "    print(\"Number of followers:\", int(df.loc[userID, \"num_followers\"]))\n",
    "    print(\"Day with the most tweets:\", int(df.loc[userID, \"day_with_most_tweets\"]))\n",
    "    print(\"Flesch Kincaid Grade:\", float(df.loc[userID, \"flesch_kincaid_grade\"]))\n",
    "    print(\"Coleman Liau Index:\", float(df.loc[userID, \"coleman_liau_index\"]))\n",
    "    print(\"Automated Readability Index:\", float(df.loc[userID, \"automated_readability_index\"]))\n",
    "    print(\"Linsear Write Formula:\", float(df.loc[userID, \"linsear_write_formula\"]))\n",
    "    print(\"Gunning Fog:\", float(df.loc[userID, \"gunning_fog\"]))\n",
    "    print(\"Average number of retweets per tweet:\", float(df.loc[userID, \"avg_num_retweets\"]))\n",
    "    print(\"Average number of favorites per tweet:\", float(df.loc[userID, \"avg_num_favorites\"]))\n",
    "    print(\"Average number of hashtags per tweet:\", float(df.loc[userID, \"avg_num_hashtags\"]))\n",
    "    print(\"Average number of emojis per tweet:\", float(df.loc[userID, \"avg_num_emojis\"]))\n",
    "    print(\"Average number of links per tweet:\", float(df.loc[userID, \"avg_num_links\"]))\n",
    "    print(\"Average number of linked pictures per tweet:\", float(df.loc[userID, \"avg_num_linked_pics\"]))\n",
    "    print(\"Percentage of positive tweets:\", float(df.loc[userID, \"percent_pos_tweets\"]))\n",
    "    print(\"Percentage of neutral tweets:\", float(df.loc[userID, \"percent_neu_tweets\"]))\n",
    "    print(\"Percentage of negative tweets:\", float(df.loc[userID, \"percent_neg_tweets\"]))\n",
    "    print(\"Average number of racist words per tweet:\", float(df.loc[userID, \"avg_racist_score\"]))\n",
    "    print(\"Average number of neutral words per tweet:\", float(df.loc[userID, \"avg_neutral_score\"]))\n",
    "\n",
    "    print(\"SDO Score:\", sdo_score)\n",
    "    print(\"RWA Score:\", rwa_score)\n",
    "    \n",
    "    print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     2,
     20,
     24,
     35,
     43,
     47,
     54,
     63,
     76
    ]
   },
   "outputs": [],
   "source": [
    "# Function definitions for calculating metrics for each user\n",
    "# day_with_most_tweets\n",
    "def updateDayFreq(daysTweetedCount, data):\n",
    "    srch = re.search(\"(\\w{3})\", data[\"created_at\"])\n",
    "    day = str(srch[1])\n",
    "    if day == \"Mon\":\n",
    "        daysTweetedCount[0] += 1\n",
    "    elif day == \"Tue\":\n",
    "        daysTweetedCount[1] += 1\n",
    "    elif day == \"Wed\":\n",
    "        daysTweetedCount[2] += 1\n",
    "    elif day == \"Thu\":\n",
    "        daysTweetedCount[3] += 1\n",
    "    elif day == \"Fri\":\n",
    "        daysTweetedCount[4] += 1\n",
    "    elif day == \"Sat\":\n",
    "        daysTweetedCount[5] += 1\n",
    "    elif day == \"Sun\":\n",
    "        daysTweetedCount[6] += 1\n",
    "    \n",
    "def getDayWMostTweets(daysTweetedCount):\n",
    "    return np.argmax(daysTweetedCount)\n",
    "\n",
    "# Readability scores\n",
    "def cleanTweet(text):\n",
    "    cleanedText = \" \".join([re.sub(\"[^a-zA-Z#']\", '', x) for x in tweet_tokenizer.tokenize(text) if\n",
    "                                 x and\n",
    "                                 not x.startswith('http') and\n",
    "                                 not x.startswith('@') and\n",
    "                                 not x.startswith('#') and\n",
    "                                 x.lower() != 'rt' and\n",
    "                                 not (x.startswith('&') and x.endswith(';'))]).strip().lower()\n",
    "    return cleanedText.lower()\n",
    "\n",
    "# flesch, coleman, automated, linsear, gunning readability scores\n",
    "def updateReadabilityScores(readabilityScores, cleanedTweet):\n",
    "    readabilityScores[0] += textstat.flesch_kincaid_grade(cleanedTweet)\n",
    "    readabilityScores[1] += textstat.coleman_liau_index(cleanedTweet)\n",
    "    readabilityScores[2] += textstat.automated_readability_index(cleanedTweet)\n",
    "    readabilityScores[3] += textstat.linsear_write_formula(cleanedTweet)\n",
    "    readabilityScores[4] += textstat.gunning_fog(cleanedTweet)\n",
    "    \n",
    "# avg_num_emojis\n",
    "def extract_emojis(text):\n",
    "    return [c for c in text if c in emoji.UNICODE_EMOJI]\n",
    "\n",
    "# avg_num_retweets, avg_num_favorites, avg_num_hashtags, avg_num_emojis\n",
    "def updateTweetFeaturesFreq(tweetFeaturesCount, data, tweet):\n",
    "    tweetFeaturesCount[0] += data[\"retweet_count\"]\n",
    "    tweetFeaturesCount[1] += data[\"favorite_count\"]\n",
    "    tweetFeaturesCount[2] += len(data[\"entities\"][\"hashtags\"])\n",
    "    tweetFeaturesCount[3] += len(extract_emojis(tweet))\n",
    "    \n",
    "# avg_num_links/avg_num_linked_pics\n",
    "def updateLinksAndPicsFreq(linksAndPicsCount, urls):\n",
    "    for url in urls:\n",
    "        m = re.search('https:\\/\\/twitter\\.com\\/i\\/web\\/status\\/', url[\"expanded_url\"])\n",
    "        if m:\n",
    "            linksAndPicsCount[1] += 1\n",
    "        else:\n",
    "            linksAndPicsCount[0] += 1\n",
    "            \n",
    "# percent_pos_tweets, percent_neu_tweets, percent_neg_tweets\n",
    "def updateSentimentFreq(sentimentCount, text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    filteredTweetText = ''.join(filter(lambda x: x in string.printable, text))\n",
    "    ss = sid.polarity_scores(filteredTweetText)\n",
    "    compoundScore = ss[\"compound\"]\n",
    "    if compoundScore > 0:\n",
    "        sentimentCount[0] += 1\n",
    "    elif compoundScore == 0:\n",
    "        sentimentCount[1] += 1\n",
    "    else:\n",
    "        sentimentCount[2] += 1\n",
    "        \n",
    "# avg_num_racist_words/avg_num_neutral_words\n",
    "def aggregateRacismResults(racismDictResults):\n",
    "    numRacistWords = racismDictResults['racist-stereotypes'] + \\\n",
    "                        racismDictResults['racist-skin_color'] + \\\n",
    "                        racismDictResults['racist-culture'] + \\\n",
    "                        racismDictResults['racist-country'] + \\\n",
    "                        racismDictResults['racist-animals'] + \\\n",
    "                        racismDictResults['racist-migration'] + \\\n",
    "                        racismDictResults['racist-nationality'] + \\\n",
    "                        racismDictResults['racist-religion'] + \\\n",
    "                        racismDictResults['racist-crime'] + \\\n",
    "                        racismDictResults['racist-race'] + \\\n",
    "                        racismDictResults['racist-diseases']\n",
    "    numNeutralWords = racismDictResults['neutral-migration'] + \\\n",
    "                        racismDictResults['neutral-skin_color'] + \\\n",
    "                        racismDictResults['neutral-country'] + \\\n",
    "                        racismDictResults['neutral-religion'] + \\\n",
    "                        racismDictResults['neutral-nationality'] \n",
    "    \n",
    "    return numRacistWords, numNeutralWords\n",
    "\n",
    "\n",
    "### AUSTIN CODE FUNCTION RELIGIOUSNESS\n",
    "def read_csv(directory):\n",
    "    religious_words = []\n",
    "    with open(directory) as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        for row in csvfile:\n",
    "            if row != 'WORSHIP,\\n':\n",
    "                religious_words.append(row[:-2].lower())\n",
    "            else:\n",
    "                religious_words.append(row[:-1].lower())\n",
    "            \n",
    "    return religious_words\n",
    "\n",
    "def is_tweet_religious(tweet,dict):\n",
    "    needed_words = 2\n",
    "    common_words = set(dict) & set(tweet.split())\n",
    "    if len(common_words) >= 2:\n",
    "        return True\n",
    "    \n",
    "def religion_score_test():\n",
    "    tweets = [\"i am not religious\", \"nope not me either\", \"holy church\", \"christians can perform miracles at church\"]\n",
    "    religionDict = read_csv(RELIGIOUS_DICTIONARY)\n",
    "    \n",
    "    print(religionDict)\n",
    "    \n",
    "    totalNumTweets = len(tweets)\n",
    "    totalReligiousTweets = 0\n",
    "    religiousScore = 0.0\n",
    "    \n",
    "    for i in range(totalNumTweets):\n",
    "        #calculate religious score for tweet\n",
    "        print(\"Processing Tweet: \" + tweets[i])\n",
    "        if is_tweet_religious(tweets[i],religionDict):\n",
    "            totalReligiousTweets += 1\n",
    "    \n",
    "    #calculations for user\n",
    "    if totalReligiousTweets and totalNumTweets:\n",
    "        religiousScore = totalReligiousTweets/totalNumTweets\n",
    "        \n",
    "    print (totalReligiousTweets)\n",
    "    print (religiousScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Function definitions for LDA\n",
    "# Print the words in their respective topics\n",
    "def printTopWords(model, featureNames, nTopWords):\n",
    "    for topicIdx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topicIdx\n",
    "        message += \" \".join([featureNames[i] for i in topic.argsort()[:-nTopWords-1:-1]])\n",
    "        print(message)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../users-new/38381682.json.gz\n",
      "../users-new/36863478.json.gz\n",
      "../users-new/36670025.json.gz\n"
     ]
    }
   ],
   "source": [
    "# Get the gzip files\n",
    "gzipFiles = [TWEETS_DIRECTORY + objname for objname in os.listdir(TWEETS_DIRECTORY) if re.search(r\".+\\.gz$\", objname)]\n",
    "for gzfilename in gzipFiles:\n",
    "    print(gzfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Load training labels and dictionaries + init tokenizer\n",
    "df = pd.read_csv(TRAIN_LABEL_FILE, dtype={'user_id': 'str'})\n",
    "racismDict = DictFeaturizer.load(RACISM_DICT_FILE)\n",
    "racismDict.rel = False\n",
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Specify feature columns in dataframe\n",
    "featureNames = [\n",
    "    \"num_tweets\",#ok\n",
    "    \"num_followers\",#ok\n",
    "    \"day_with_most_tweets\",#ok    \n",
    "    \"flesch_kincaid_grade\",#ok\n",
    "    \"coleman_liau_index\",#ok\n",
    "    \"automated_readability_index\",#ok\n",
    "    \"linsear_write_formula\",#ok\n",
    "    \"gunning_fog\",#ok\n",
    "    \"avg_num_retweets\",#ok\n",
    "    \"avg_num_favorites\",#ok\n",
    "    \"avg_num_hashtags\",#ok\n",
    "    \"avg_num_emojis\",#ok\n",
    "    \"avg_num_links\",#ok\n",
    "    \"avg_num_linked_pics\",#ok\n",
    "    \"percent_pos_tweets\",#ok\n",
    "    \"percent_neu_tweets\",#ok\n",
    "    \"percent_neg_tweets\",#ok\n",
    "    \"avg_racist_score\",#ok\n",
    "    \"avg_neutral_score\",#ok\n",
    "    \"avg_sexist_score\",#Habeeb\n",
    "    \"avg_relig_score\"#Austin\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Init/reset all fields to 0.0\n",
    "for featName in featureNames:\n",
    "    df[featName] = np.zeros(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                sdo       rwa  num_tweets  num_followers  \\\n",
      "user_id                                                    \n",
      "12432922   0.585655  0.175252           0              0   \n",
      "172018245  0.808501  0.567951           0              0   \n",
      "929862361  0.083294  0.587029           0              0   \n",
      "\n",
      "           day_with_most_tweets  flesch_kincaid_grade  coleman_liau_index  \\\n",
      "user_id                                                                     \n",
      "12432922                      0                   0.0                 0.0   \n",
      "172018245                     0                   0.0                 0.0   \n",
      "929862361                     0                   0.0                 0.0   \n",
      "\n",
      "           automated_readability_index  linsear_write_formula  gunning_fog  \\\n",
      "user_id                                                                      \n",
      "12432922                           0.0                    0.0          0.0   \n",
      "172018245                          0.0                    0.0          0.0   \n",
      "929862361                          0.0                    0.0          0.0   \n",
      "\n",
      "           ...  avg_num_emojis  avg_num_links  avg_num_linked_pics  \\\n",
      "user_id    ...                                                       \n",
      "12432922   ...             0.0            0.0                  0.0   \n",
      "172018245  ...             0.0            0.0                  0.0   \n",
      "929862361  ...             0.0            0.0                  0.0   \n",
      "\n",
      "           percent_pos_tweets  percent_neu_tweets  percent_neg_tweets  \\\n",
      "user_id                                                                 \n",
      "12432922                  0.0                 0.0                 0.0   \n",
      "172018245                 0.0                 0.0                 0.0   \n",
      "929862361                 0.0                 0.0                 0.0   \n",
      "\n",
      "           avg_racist_score  avg_neutral_score  avg_sexist_score  \\\n",
      "user_id                                                            \n",
      "12432922                0.0                0.0               0.0   \n",
      "172018245               0.0                0.0               0.0   \n",
      "929862361               0.0                0.0               0.0   \n",
      "\n",
      "           avg_relig_score  \n",
      "user_id                     \n",
      "12432922               0.0  \n",
      "172018245              0.0  \n",
      "929862361              0.0  \n",
      "\n",
      "[3 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Correct the data types in the dataframe + set df index\n",
    "df = df.astype({\"num_tweets\": int,\n",
    "                \"num_followers\": int,\n",
    "                \"num_followers\": int,\n",
    "                \"day_with_most_tweets\": int\n",
    "               })\n",
    "df = df.set_index(\"user_id\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     15
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current twitter user file: ../users-new/38381682.json.gz\n",
      "Number of tweets: 420\n",
      "Number of followers: 2979\n",
      "Day with the most tweets: 5\n",
      "Flesch Kincaid Grade: 6.575952380952383\n",
      "Coleman Liau Index: 6.223285714285711\n",
      "Automated Readability Index: 6.4921428571428565\n",
      "Linsear Write Formula: 6.916666666666667\n",
      "Gunning Fog: 7.9156428571428705\n",
      "Average number of retweets per tweet: 18.873809523809523\n",
      "Average number of favorites per tweet: 0.6428571428571429\n",
      "Average number of hashtags per tweet: 0.6857142857142857\n",
      "Average number of emojis per tweet: 0.01904761904761905\n",
      "Average number of links per tweet: 0.29523809523809524\n",
      "Average number of linked pictures per tweet: 0.05\n",
      "Percentage of positive tweets: 0.4023809523809524\n",
      "Percentage of neutral tweets: 0.3976190476190476\n",
      "Percentage of negative tweets: 0.2\n",
      "Average number of racist words per tweet: 0.319047619047619\n",
      "Average number of neutral words per tweet: 0.1976190476190476\n",
      "SDO Score: 0.40267886799999997\n",
      "RWA Score: 0.977335215\n",
      "---------------------------------------------------------------------\n",
      "Current twitter user file: ../users-new/36863478.json.gz\n",
      "Number of tweets: 3234\n",
      "Number of followers: 10361\n",
      "Day with the most tweets: 5\n",
      "Flesch Kincaid Grade: 8.532096474953624\n",
      "Coleman Liau Index: 7.410352504638213\n",
      "Automated Readability Index: 7.791403834261006\n",
      "Linsear Write Formula: 8.970315398886827\n",
      "Gunning Fog: 9.471873840445216\n",
      "Average number of retweets per tweet: 245.28973407544837\n",
      "Average number of favorites per tweet: 0.1360544217687075\n",
      "Average number of hashtags per tweet: 0.15275200989486704\n",
      "Average number of emojis per tweet: 0.008658008658008658\n",
      "Average number of links per tweet: 0.12059369202226346\n",
      "Average number of linked pictures per tweet: 0.6898577612863327\n",
      "Percentage of positive tweets: 0.26468769325912184\n",
      "Percentage of neutral tweets: 0.2504638218923933\n",
      "Percentage of negative tweets: 0.48484848484848486\n",
      "Average number of racist words per tweet: 0.3209647495361781\n",
      "Average number of neutral words per tweet: 0.1280148423005566\n",
      "SDO Score: 0.380268166\n",
      "RWA Score: 0.251323511\n",
      "---------------------------------------------------------------------\n",
      "Current twitter user file: ../users-new/36670025.json.gz\n",
      "Number of tweets: 3217\n",
      "Number of followers: 2365502\n",
      "Day with the most tweets: 3\n",
      "Flesch Kincaid Grade: 7.010009325458512\n",
      "Coleman Liau Index: 7.900161641280721\n",
      "Automated Readability Index: 8.241405035747578\n",
      "Linsear Write Formula: 7.0713397575380785\n",
      "Gunning Fog: 8.461056885296818\n",
      "Average number of retweets per tweet: 172.33944668946222\n",
      "Average number of favorites per tweet: 202.53590301523158\n",
      "Average number of hashtags per tweet: 0.1806030463164439\n",
      "Average number of emojis per tweet: 0.3870065278209512\n",
      "Average number of links per tweet: 0.37892446378613615\n",
      "Average number of linked pictures per tweet: 0.3372707491451663\n",
      "Percentage of positive tweets: 0.3114703139571029\n",
      "Percentage of neutral tweets: 0.3960211377059372\n",
      "Percentage of negative tweets: 0.2925085483369599\n",
      "Average number of racist words per tweet: 0.4009947155735157\n",
      "Average number of neutral words per tweet: 0.3139571028908921\n",
      "SDO Score: 0.02671738\n",
      "RWA Score: 0.322228218\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for each user\n",
    "for userTweetsFile in gzipFiles:\n",
    "    # Get data and tweets\n",
    "    userID = getUserID(TWEETS_DIRECTORY, userTweetsFile)\n",
    "    dataAndTweets = getUserTweetsAndData(userTweetsFile)\n",
    "    data = dataAndTweets[0]\n",
    "    tweets = dataAndTweets[1]\n",
    "    totalNumTweets = len(data)\n",
    "    daysTweetedCount = np.zeros(7)   # [mon, tue, ..., sun]\n",
    "    sentimentCount = np.zeros(3)     # [#pos, #neu, #neg]\n",
    "    linksAndPicsCount = np.zeros(2)  # [#links, #pics]\n",
    "    readabilityScores = np.zeros(5)  # [flesch, coleman, automated, linsear, gunning]\n",
    "    tweetFeaturesCount = np.zeros(4) # [#retweets, #favorites, #hashtags, #emojis]\n",
    "    totalReligiousTweets = 0 #Amount of religious tweets for a user\n",
    "    religiousScore = 0.0 #user religious socre\n",
    "    \n",
    "    religionDict = read_csv(RELIGIOUS_DICTIONARY) #reads in religion dict may need to change pos for clarity\n",
    "    \n",
    "    # Look through each tweet\n",
    "    for i in range(totalNumTweets):\n",
    "        \n",
    "        # Get the day of the week tweeted\n",
    "        updateDayFreq(daysTweetedCount, data[i])\n",
    "\n",
    "        # Calculate average readability scores\n",
    "        cleanedTweet = cleanTweet(tweets[i])\n",
    "        updateReadabilityScores(readabilityScores, cleanedTweet)\n",
    "        \n",
    "        # Get the number retweeted/favorited/hashtags/emojis\n",
    "        updateTweetFeaturesFreq(tweetFeaturesCount, data[i], tweets[i])\n",
    "        \n",
    "        # Get the number of links\n",
    "        updateLinksAndPicsFreq(linksAndPicsCount, data[i][\"entities\"][\"urls\"])\n",
    "        \n",
    "        # Check if tweet is positive, negative, or neutral\n",
    "        updateSentimentFreq(sentimentCount, cleanedTweet)\n",
    "        \n",
    "        # Count the number of racist/neutral words used\n",
    "        racismDictResults = racismDict.transform(cleanedTweet.split())\n",
    "        aggregatedRacismResults = aggregateRacismResults(racismDictResults)\n",
    "        df.loc[userID, \"avg_racist_score\"] += aggregatedRacismResults[0]\n",
    "        df.loc[userID, \"avg_neutral_score\"] += aggregatedRacismResults[1]\n",
    "        \n",
    "        if is_tweet_religious(cleanedTweet,religionDict):\n",
    "            totalReligiousTweets += 1\n",
    "        \n",
    "    # User-level metrics\n",
    "    # Get the number of tweets total/number of followers\n",
    "    df.loc[userID, \"num_tweets\"] = totalNumTweets\n",
    "    df.loc[userID, \"num_followers\"] = data[i][\"user\"][\"followers_count\"]\n",
    "    \n",
    "    # Get the day that on which the user tweeted most\n",
    "    df.loc[userID, \"day_with_most_tweets\"] = getDayWMostTweets(daysTweetedCount)\n",
    "    \n",
    "    # Get the average readability scores for a user\n",
    "    readabilityScores /= totalNumTweets\n",
    "    df.loc[userID, \"flesch_kincaid_grade\"] = readabilityScores[0]\n",
    "    df.loc[userID, \"coleman_liau_index\"] = readabilityScores[1]\n",
    "    df.loc[userID, \"automated_readability_index\"] = readabilityScores[2]\n",
    "    df.loc[userID, \"linsear_write_formula\"] = readabilityScores[3]\n",
    "    df.loc[userID, \"gunning_fog\"] = readabilityScores[4]\n",
    "    \n",
    "    # Get the average number of retweets/favorites/hashtags/emojis per tweet\n",
    "    tweetFeaturesCount /= totalNumTweets\n",
    "    df.loc[userID, \"avg_num_retweets\"] = tweetFeaturesCount[0]\n",
    "    df.loc[userID, \"avg_num_favorites\"] = tweetFeaturesCount[1]\n",
    "    df.loc[userID, \"avg_num_hashtags\"] = tweetFeaturesCount[2]\n",
    "    df.loc[userID, \"avg_num_emojis\"] = tweetFeaturesCount[3]\n",
    "    \n",
    "    # Get the average number of links/linked pictures per tweet\n",
    "    linksAndPicsCount /= totalNumTweets\n",
    "    df.loc[userID, \"avg_num_links\"] = linksAndPicsCount[0]\n",
    "    df.loc[userID, \"avg_num_linked_pics\"] = linksAndPicsCount[1]\n",
    "    \n",
    "    # Get the percentage of pos/neu/neg tweets\n",
    "    sentimentCount /= totalNumTweets\n",
    "    df.loc[userID, \"percent_pos_tweets\"] = sentimentCount[0]\n",
    "    df.loc[userID, \"percent_neu_tweets\"] = sentimentCount[1]\n",
    "    df.loc[userID, \"percent_neg_tweets\"] = sentimentCount[2]\n",
    "    \n",
    "    # Get the average number of racist/neutral words per tweet\n",
    "    df.loc[userID, \"avg_racist_score\"] /= totalNumTweets\n",
    "    df.loc[userID, \"avg_neutral_score\"] /= totalNumTweets\n",
    "    \n",
    "    #Get religious score of user\n",
    "    df.loc[userID, \"avg_religous_score\"] = totalReligiousTweets / totalNumTweets\n",
    "    \n",
    "    # Print all a user's data\n",
    "    printUserStats(TWEETS_DIRECTORY, userTweetsFile, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.02678868e-01 9.77335215e-01 4.20000000e+02 2.97900000e+03\n",
      "  5.00000000e+00 6.57595238e+00 6.22328571e+00 6.49214286e+00\n",
      "  6.91666667e+00 7.91564286e+00 1.88738095e+01 6.42857143e-01\n",
      "  6.85714286e-01 1.90476190e-02 2.95238095e-01 5.00000000e-02\n",
      "  4.02380952e-01 3.97619048e-01 2.00000000e-01 3.19047619e-01\n",
      "  1.97619048e-01 0.00000000e+00 0.00000000e+00 9.52380952e-03]\n",
      " [3.80268166e-01 2.51323511e-01 3.23400000e+03 1.03610000e+04\n",
      "  5.00000000e+00 8.53209647e+00 7.41035250e+00 7.79140383e+00\n",
      "  8.97031540e+00 9.47187384e+00 2.45289734e+02 1.36054422e-01\n",
      "  1.52752010e-01 8.65800866e-03 1.20593692e-01 6.89857761e-01\n",
      "  2.64687693e-01 2.50463822e-01 4.84848485e-01 3.20964750e-01\n",
      "  1.28014842e-01 0.00000000e+00 0.00000000e+00 5.84415584e-02]\n",
      " [2.67173800e-02 3.22228218e-01 3.21700000e+03 2.36550200e+06\n",
      "  3.00000000e+00 7.01000933e+00 7.90016164e+00 8.24140504e+00\n",
      "  7.07133976e+00 8.46105689e+00 1.72339447e+02 2.02535903e+02\n",
      "  1.80603046e-01 3.87006528e-01 3.78924464e-01 3.37270749e-01\n",
      "  3.11470314e-01 3.96021138e-01 2.92508548e-01 4.00994716e-01\n",
      "  3.13957103e-01 0.00000000e+00 0.00000000e+00 1.55424308e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Get complete rows of data from DF and convert to np_array\n",
    "colNames = [\"user_id\", \"sdo\", \"rwa\"] + featureNames\n",
    "newDF = pd.DataFrame(columns=colNames)\n",
    "newDF = newDF.set_index(\"user_id\")\n",
    "\n",
    "for userTweetsFile in gzipFiles:\n",
    "    userID = getUserID(TWEETS_DIRECTORY, userTweetsFile)\n",
    "    newDF = newDF.append(df.loc[userID])\n",
    "    \n",
    "npDF = newDF.values\n",
    "print(npDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 22)\n",
      "(2, 2)\n",
      "(1, 22)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training/testing sets\n",
    "trainSize = int(.75*npDF.shape[0])\n",
    "Xtrain = npDF[:trainSize, 2:]\n",
    "ytrain = npDF[:trainSize, :2]\n",
    "Xtest = npDF[trainSize:, 2:]\n",
    "ytest = npDF[trainSize:, :2]\n",
    "\n",
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -5.85731589 -201.81994718]]\n"
     ]
    }
   ],
   "source": [
    "# Run Linear Regression\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(Xtrain, ytrain)\n",
    "yPred = regr.predict(Xtest)\n",
    "print(yPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[-1.00960423e-06 -2.64850690e-06  0.00000000e+00 -7.01823507e-10\n",
      "  -4.25894688e-10 -4.66147611e-10 -7.36806128e-10 -5.58343064e-10\n",
      "  -8.12332888e-08  1.81830195e-10  1.91215696e-10  3.72757448e-12\n",
      "   6.26587519e-11 -2.29567556e-10  4.94014558e-11  5.27962111e-11\n",
      "  -1.02197667e-10 -6.87826243e-13  2.49725302e-11  0.00000000e+00\n",
      "   0.00000000e+00 -1.75506632e-11]\n",
      " [-3.27068954e-05 -8.58003916e-05  0.00000000e+00 -2.27361053e-08\n",
      "  -1.37971817e-08 -1.51012057e-08 -2.38693938e-08 -1.80879474e-08\n",
      "  -2.63161406e-06  5.89052722e-09  6.19457761e-09  1.20757605e-10\n",
      "   2.02987784e-09 -7.43701523e-09  1.60039766e-09  1.71037334e-09\n",
      "  -3.31077100e-09 -2.22826533e-11  8.09004073e-10  0.00000000e+00\n",
      "   0.00000000e+00 -5.68567057e-10]]\n",
      "Mean squared error: 20448.04\n",
      "Variance score: 0.00\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients: \\n', regr.coef_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(ytest, yPred))\n",
    "print('Variance score: %.2f' % r2_score(ytest, yPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't run past here, still broken from multiple changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf shape: (3217, 11337)\n",
      "0.08385362297850163\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction (old)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "tf = vectorizer.fit_transform(tweets)\n",
    "print(\"tf shape:\", tf.shape)\n",
    "\n",
    "y = np.empty(tf.shape[0])\n",
    "\n",
    "# Give each tweet the personality score of the user\n",
    "if TRAIN_LABEL_FILE == \"\":\n",
    "    # Randomly fill score if none provided\n",
    "    #y.fill(np.random.uniform(size=1)[0])\n",
    "    y = np.random.uniform(size=tf.shape[0])\n",
    "    print(y[0])\n",
    "else:\n",
    "    #y.fill(float(sdo_score))\n",
    "    y = np.random.uniform(size=tf.shape[0])\n",
    "    print(y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Feature selection (old)\n",
    "\"\"\"\n",
    "#tfNew = SelectKBest(f_regression, k=10).fit_transform(tf, y)\n",
    "selPercent = SelectPercentile(f_regression, percentile=10)\n",
    "tfNew = selPercent.fit_transform(tf, y)\n",
    "print(\"tfNew shape:\", tfNew.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics in LDA model:\n",
      "Topic #0: tomi_adeyemi household frfe3m9az3 sounds wait earth dreams samuel adeyemimichael turns regional rock idea hope eto happiness perfect eliudkipchoge dangers congratulations\n",
      "Topic #1: injury newcastle undergoes squad sangare zmq99ob4th moise_katumbi nomination woxpknkgiw mygjsbwvex boat museveni spain tragedy toure turn ghanaians draw vincent coding\n",
      "Topic #2: rwanda 16 genocide rwandan shock kenyans force thomas rwigara diane open athlete plane malawi known later weekend albinism bans businesses\n",
      "Topic #3: https rt africa nigeria south president year women says world people congo new kenya bbc dr election 2018 uganda cameroon\n",
      "Topic #4: thanks comments saxophone favourite virtuoso osei wr59aam8fw teddy sharing watching prevent franklin aretha georgiendirangu comedian game yaolri ministry poaching investigation\n",
      "Topic #5: https joins rt sierra leone forward minister nigerian big mosalah music yes loan burundi bbcworldservice boko haram nyom 6p3fyfxxor schalke\n",
      "Topic #6: league champions hero goals game story manutd maasai test match built tell mane lost sadio couple cancer lions forest season\n",
      "Topic #7: residents arresting vandalising uefapa5ugi sys skin asiricomedy officialarole couldn tried diamond title modric brand charles anthonyfjoshua jose fees http marvel\n",
      "Topic #8: https african today proverb sent podcast water man bobi wine like died mp ghanaian star somali child person rt win\n",
      "Topic #9: thank trees roasting eid sheep niger save midfielder remembering urged rangers franklin vwgykazjft hbhgonc4gj aretha revellers nhoy4gzupa rlpwke9yxi thigh l5n5yyvydl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run LDA with original tf\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(tf)\n",
    "print(\"Topics in LDA model:\")\n",
    "tfFeatureNames = vectorizer.get_feature_names()\n",
    "printTopWords(lda, tfFeatureNames, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfNew' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-746f85a98811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                 random_state=0)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlda2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfNew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Topics in new LDA model:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtfFeatureNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfNew' is not defined"
     ]
    }
   ],
   "source": [
    "# Run LDA with selected tf\n",
    "'''\n",
    "lda2 = LatentDirichletAllocation(n_components=10, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda2.fit(tfNew)\n",
    "print(\"Topics in new LDA model:\")\n",
    "tfFeatureNames = vectorizer.get_feature_names()\n",
    "retained = selPercent.get_support(True)\n",
    "newFeatureNames = []\n",
    "\n",
    "# Get the list of selected feature names \n",
    "for idx in retained:\n",
    "    newFeatureNames.append(tfFeatureNames[idx])\n",
    "\n",
    "printTopWords(lda2, newFeatureNames, 20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/readability-index-pythonnlp/\n",
    "- Referenced code for calculating readability score\n",
    "- There are 4 readability formulas we can use\n",
    "    - flesch_reading_ease(text)\n",
    "    - gunning_fog(text)\n",
    "    - smog_index(text)\n",
    "    - dale_chall_readability_score(text)\n",
    "\n",
    "@article{tulkens2016automated,\n",
    "  title={The automated detection of racist discourse in dutch social media},\n",
    "  author={Tulkens, St{\\'e}phan and Hilte, Lisa and Lodewyckx, Elise and Verhoeven, Ben and Daelemans, Walter},\n",
    "  journal={Computational Linguistics in the Netherlands Journal},\n",
    "  volume={6},\n",
    "  number={1},\n",
    "  pages={3--20},\n",
    "  year={2016}\n",
    "}\n",
    "- Racism dictionary\n",
    "\n",
    "https://stackoverflow.com/questions/43146528/how-to-extract-all-the-emojis-from-text\n",
    "- Code used to extract emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning\n",
    "SDO 0 \n",
    "RWA 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.20000000e+02 2.97900000e+03 5.00000000e+00 6.57595238e+00\n",
      "  6.22328571e+00 6.49214286e+00 6.91666667e+00 7.91564286e+00\n",
      "  1.88738095e+01 6.42857143e-01 6.85714286e-01 1.90476190e-02\n",
      "  2.95238095e-01 5.00000000e-02 4.02380952e-01 3.97619048e-01\n",
      "  2.00000000e-01 3.19047619e-01 1.97619048e-01 0.00000000e+00\n",
      "  0.00000000e+00 9.52380952e-03]\n",
      " [3.23400000e+03 1.03610000e+04 5.00000000e+00 8.53209647e+00\n",
      "  7.41035250e+00 7.79140383e+00 8.97031540e+00 9.47187384e+00\n",
      "  2.45289734e+02 1.36054422e-01 1.52752010e-01 8.65800866e-03\n",
      "  1.20593692e-01 6.89857761e-01 2.64687693e-01 2.50463822e-01\n",
      "  4.84848485e-01 3.20964750e-01 1.28014842e-01 0.00000000e+00\n",
      "  0.00000000e+00 5.84415584e-02]\n",
      " [3.21700000e+03 2.36550200e+06 3.00000000e+00 7.01000933e+00\n",
      "  7.90016164e+00 8.24140504e+00 7.07133976e+00 8.46105689e+00\n",
      "  1.72339447e+02 2.02535903e+02 1.80603046e-01 3.87006528e-01\n",
      "  3.78924464e-01 3.37270749e-01 3.11470314e-01 3.96021138e-01\n",
      "  2.92508548e-01 4.00994716e-01 3.13957103e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.55424308e-03]]\n",
      "[[0.40267887 0.97733521]\n",
      " [0.38026817 0.25132351]\n",
      " [0.02671738 0.32222822]]\n",
      "[0.08385362 0.21364449 0.05506601 ... 0.14455107 0.29574909 0.85298077]\n"
     ]
    }
   ],
   "source": [
    "print (npDF [0:,2:])\n",
    "print(npDF [0:,:2])\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeRegressor()\n",
    "#clf = clf.fit(Xtrain,ytrain)\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=2)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor()\n",
    "#clf = clf.fit(Xtrain,ytrain)\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=2)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Ridge(alpha = 1.0)\n",
    "#clf = clf.fit(Xtrain,ytrain)\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=2)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.96400213e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-2.57999895e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Lars(n_nonzero_coefs=1)\n",
    "clf = clf.fit(Xtrain,ytrain)\n",
    "#scores = cross_val_score(clf, Xtrain, y, cv=2)\n",
    "#print(scores)\n",
    "print(clf.coef_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.58883216e-05  6.79131449e-05  0.00000000e+00  1.79961931e-08\n",
      "  1.09208126e-08  1.19529801e-08  1.88932192e-08  1.43170605e-08\n",
      "  2.08298801e-06 -4.66249887e-09 -4.90316232e-09 -9.55826493e-11\n",
      " -1.60669882e-09  5.88658262e-09 -1.26675457e-09 -1.35380306e-09\n",
      "  2.62055763e-09  1.76372746e-11 -6.40346855e-10  0.00000000e+00\n",
      "  0.00000000e+00  4.50034973e-10]\n",
      "[-5.80896862e-06 -1.52387372e-05  0.00000000e+00 -4.03808801e-09\n",
      " -2.45047396e-09 -2.68207756e-09 -4.23936782e-09 -3.21254334e-09\n",
      " -4.67392680e-07  1.04619798e-09  1.10019941e-09  2.14473777e-11\n",
      "  3.60520206e-10 -1.32086484e-09  2.84241586e-10  3.03774019e-10\n",
      " -5.88015605e-10 -3.95755183e-12  1.43684664e-10  0.00000000e+00\n",
      "  0.00000000e+00 -1.00981403e-10]\n"
     ]
    }
   ],
   "source": [
    "clf_SDO = linear_model.BayesianRidge(compute_score=True)\n",
    "clf_SDO = clf.fit(Xtrain,ytrain[0,])\n",
    "#scores = cross_val_score(clf, Xtrain, y, cv=2)\n",
    "#print(scores)\n",
    "print(clf.coef_) \n",
    "\n",
    "clf_RWA = linear_model.BayesianRidge(compute_score=True)\n",
    "clf_RWA = clf.fit(Xtrain,ytrain[1,])\n",
    "#scores = cross_val_score(clf, Xtrain, y, cv=2)\n",
    "#print(scores)\n",
    "print(clf.coef_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-df2fa739814b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf_SDO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf_SDO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1287\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m   1288\u001b[0m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0;32m-> 1289\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    169\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    170\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "clf_SDO = linear_model.LogisticRegression()\n",
    "clf_SDO = clf.fit(Xtrain,ytrain[0])\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=2)\n",
    "print(scores)\n",
    "print(clf.coef_) \n",
    "\n",
    "clf_RWA = linear_model.LogisticRegression()\n",
    "clf_RWA = clf.fit(Xtrain,ytrain[1])\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=2)\n",
    "print(scores)\n",
    "print(clf.coef_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
