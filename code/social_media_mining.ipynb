{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updates\n",
    "#### (3/26/19)\n",
    "- Separated urls into links and linked pictures\n",
    "- Changed racist word count to regular frequency\n",
    "- Racist/neutral scores are aggregated\n",
    "- Time tweet created feature removed\n",
    "- Corrected a few data types in the user-feature dataframe\n",
    "- Replaced regular variables with np.arrays when calculating metrics to shorten script\n",
    "- Specify racism dictionary path in cell under \"User-defined Variables\"\n",
    "\n",
    "#### (4/1/19)\n",
    "- Plotted correlation coefficients matrix\n",
    "\n",
    "#### (4/8/19)\n",
    "Added two features: hate-speech and offensive language tweets\n",
    "- https://github.com/t-davidson/hate-speech-and-offensive-language\n",
    "    - Code and data in this repo was referenced and used\n",
    "- The script and files provided to run their pickled classifier on new data in their classifier directory could not be used\n",
    "    - There were multiple bugs in the script (2.7 to 3.6 incompatibility (despite using 2to3 conversion), pickled models provided were unusable, input feature generation function broken, etc.)\n",
    "- Their \"Automated Hate Speech Detection and the Problem of Offensive Language Python 3.6\" notebook was used to:\n",
    "    - Re-train their classifier with fixed input dimensions\n",
    "    - Generate a new pickled file for the best model chosen (overall 75.79% accuracy, compared to their average of 82.33% accuracy; drop in accuracy was most likely due to the removal of TF-IDF and POS features used in pickled model)\n",
    "    - Calculate percentage of tweets classified as hate-speech \n",
    "    - Calculate percentage of tweets classified as offensive language \n",
    "    \n",
    "#### (4/10/19)\n",
    "- Integrated Austin's code for classifying a tweet as religious\n",
    "- Vectorized metric calculation functions to speed up program (~7.9x faster)\n",
    "    - Original runtime: 587.108s\n",
    "    - New runtime: 74.172s\n",
    "- Cleaned up code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### User-defined Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Specify filenames and directories here\n",
    "# Specify the directory containing user .json + .gz files\n",
    "TWEETS_DIRECTORY = \"../results/users_tweets_metadata/\"\n",
    "\n",
    "# Specify the name of the CSV file containing personality scores for each user\n",
    "TRAIN_LABEL_FILE = \"../data/train_labels_rand.csv\"\n",
    "\n",
    "# Specify the name of the CSV file containing dictionary words related to racism\n",
    "RACISM_DICT_FILE = \"../data/racism_dictionary.csv\"\n",
    "\n",
    "# Specify the name of the CSV file containing dictionary words related to religiosity\n",
    "RELIGIOUS_DICTIONARY = \"../data/religious_corpus.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program Begins Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports here\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from dictfeaturizer import DictFeaturizer\n",
    "from nltk import TweetTokenizer\n",
    "from textstat.textstat import textstat\n",
    "from sklearn.externals import joblib\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import operator\n",
    "import gzip\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Class to load into np vectorizer with corresponding function\n",
    "class ReligiousityDict:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.religious_words = []\n",
    "        \n",
    "    def read_csv(self):\n",
    "        religious_words = []\n",
    "        with open(self.directory) as csvfile:\n",
    "            readCSV = csv.reader(csvfile, delimiter=',')\n",
    "            for row in csvfile:\n",
    "                if row != 'WORSHIP,\\n':\n",
    "                    religious_words.append(row[:-2].lower())\n",
    "                else:\n",
    "                    religious_words.append(row[:-1].lower())\n",
    "        self.religious_words = religious_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     21,
     30,
     49,
     58,
     69,
     76,
     93,
     99,
     108,
     113,
     120,
     145
    ]
   },
   "outputs": [],
   "source": [
    "# Function definitions for calculating metrics\n",
    "# Get the day a tweet was created\n",
    "def getDayTweeted(data):\n",
    "    srch = re.search(\"(\\w{3})\", data[\"created_at\"])\n",
    "    day = str(srch[1])\n",
    "    if day == \"Mon\":\n",
    "        return 0\n",
    "    elif day == \"Tue\":\n",
    "        return 1\n",
    "    elif day == \"Wed\":\n",
    "        return 2\n",
    "    elif day == \"Thu\":\n",
    "        return 3\n",
    "    elif day == \"Fri\":\n",
    "        return 4\n",
    "    elif day == \"Sat\":\n",
    "        return 5\n",
    "    elif day == \"Sun\":\n",
    "        return 6\n",
    "    \n",
    "# Get the day most tweets were created on\n",
    "def getDayTweetedMost(data):\n",
    "    vgetDayTweeted = np.vectorize(getDayTweeted)\n",
    "    daysTweeted = vgetDayTweeted(data)\n",
    "    day, counts = np.unique(daysTweeted, return_counts=True)\n",
    "    dayCount = dict(zip(day, counts))\n",
    "    sortedDayCount = sorted(dayCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedDayCount[0][0]\n",
    "\n",
    "# Compute flesch/coleman/automated/linsear/gunning readability scores\n",
    "def getReadabilityScore(mode, tweets):\n",
    "    vreadabilityFunc = None\n",
    "    if mode == 'flesch':\n",
    "        vreadabilityFunc = np.vectorize(textstat.flesch_kincaid_grade)\n",
    "    elif mode == 'coleman':\n",
    "        vreadabilityFunc = np.vectorize(textstat.coleman_liau_index)\n",
    "    elif mode == 'automated':\n",
    "        vreadabilityFunc = np.vectorize(textstat.automated_readability_index)\n",
    "    elif mode == 'linsear':\n",
    "        vreadabilityFunc = np.vectorize(textstat.linsear_write_formula)\n",
    "    elif mode == 'gunning':\n",
    "        vreadabilityFunc = np.vectorize(textstat.gunning_fog)\n",
    "    else:\n",
    "        print(\"Unknown mode.\")\n",
    "    \n",
    "    avgScore = vreadabilityFunc(tweets).sum() / len(tweets)\n",
    "    return avgScore\n",
    "\n",
    "# Get the number of linked pictures in a tweet\n",
    "def getNumPics(urls):\n",
    "    numPics = 0\n",
    "    for url in urls:\n",
    "        m = re.search('https:\\/\\/twitter\\.com\\/i\\/web\\/status\\/', url[\"expanded_url\"])\n",
    "        if m:\n",
    "            numPics += 1\n",
    "    return numPics\n",
    "    \n",
    "# Get the sentiment of a tweet\n",
    "def getSentiment(tweet, sid):\n",
    "    ss = sid.polarity_scores(tweet)\n",
    "    compoundScore = ss[\"compound\"]\n",
    "    if compoundScore > 0:\n",
    "        return 1\n",
    "    elif compoundScore == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# Create a dictionary that has counts of each sentiment (1: pos, 0: neu: -1: neg)\n",
    "def getSentimentFreq(tweets, sid):\n",
    "    vgetSentiment = np.vectorize(lambda t, sid: getSentiment(t, sid))\n",
    "    sentiments = vgetSentiment(tweets, sid)\n",
    "    unique, counts = np.unique(sentiments, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "# Count total racist words in a tweet\n",
    "def aggregateRacismResults(tweet, racismDict):\n",
    "    racismDictResults = racismDict.transform(tweet.split())\n",
    "    numRacistWords = racismDictResults['racist-stereotypes'] + \\\n",
    "                        racismDictResults['racist-skin_color'] + \\\n",
    "                        racismDictResults['racist-culture'] + \\\n",
    "                        racismDictResults['racist-country'] + \\\n",
    "                        racismDictResults['racist-animals'] + \\\n",
    "                        racismDictResults['racist-migration'] + \\\n",
    "                        racismDictResults['racist-nationality'] + \\\n",
    "                        racismDictResults['racist-religion'] + \\\n",
    "                        racismDictResults['racist-crime'] + \\\n",
    "                        racismDictResults['racist-race'] + \\\n",
    "                        racismDictResults['racist-diseases']\n",
    "    return numRacistWords\n",
    "\n",
    "'''\n",
    "# Get the average number of racist words in a tweet\n",
    "def getAvgNumRacistWords(tweets, racismDict):\n",
    "    vfunc = np.vectorize(aggregateRacismResults)\n",
    "    return vfunc(tweets, racismDict).sum() / len(tweets)\n",
    "'''\n",
    "\n",
    "# Classify a tweet as religious or not (Austin's)\n",
    "def is_tweet_religious(tweet, religionDict):\n",
    "    needed_words = 2\n",
    "    common_words = set(religionDict.religious_words) & set(tweet.split())\n",
    "    if len(common_words) >= needed_words:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# Get the percentage of religious tweets\n",
    "def getPercentReligious(tweets, religionDict):\n",
    "    vfunc = np.vectorize(is_tweet_religious)\n",
    "    return vfunc(tweets, religionDict).sum() / len(tweets)\n",
    "\n",
    "# Classify tweet as hate-speech(0), offensive language(1), or neither(2) and create a counts dictionary\n",
    "def getHsolClass(tweets, hsolModel):\n",
    "    transformedTweet = transform_inputs(tweets)\n",
    "    predictedClasses = hsolModel.predict(transformedTweet)\n",
    "    unique, counts = np.unique(predictedClasses, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "# Get the average number of retweets/favorites/hashtags/links/pics/emojis\n",
    "def getAvgNum(item, data, racismDict=None):\n",
    "    vfunc = None\n",
    "    if item == 'retweets':\n",
    "        vfunc = np.vectorize(lambda d: d[\"retweet_count\"])\n",
    "    elif item == 'favorites':\n",
    "        vfunc = np.vectorize(lambda d: d[\"favorite_count\"])\n",
    "    elif item == 'hashtags':\n",
    "        vfunc = np.vectorize(lambda d: len(d[\"entities\"][\"hashtags\"]))\n",
    "    elif item == 'links':\n",
    "        vfunc = np.vectorize(lambda d: len(d[\"entities\"][\"urls\"]) - getNumPics(d[\"entities\"][\"urls\"]))\n",
    "    elif item == 'pics':\n",
    "        vfunc = np.vectorize(lambda d: getNumPics(d[\"entities\"][\"urls\"]))\n",
    "    elif item == 'emojis':\n",
    "        # \"data\" input must be tweets for this case\n",
    "        vfunc = np.vectorize(lambda t: len([c for c in t if c in emoji.UNICODE_EMOJI]))\n",
    "    elif item == 'racist':\n",
    "        # \"data\" input must be tweets for this case\n",
    "        vfunc = np.vectorize(aggregateRacismResults)\n",
    "        return vfunc(tweets, racismDict).sum() / len(tweets)\n",
    "    else:\n",
    "        print(\"Unknown mode:\", item)\n",
    "        return 0.0\n",
    "    return vfunc(data).sum() / len(data)\n",
    "\n",
    "# Get the percentage of pos/neu/neg/religious/hatespeech/offensive tweets\n",
    "def getPercent(item, tweets, sentimentFreq=None, hsolFreq=None, religionDict=None):\n",
    "    if item == 'pos' and 1 in sentimentFreq:\n",
    "        return sentimentFreq[1] / len(tweets)\n",
    "    elif item == 'neu' and 0 in sentimentFreq:\n",
    "        return sentimentFreq[0] / len(tweets)\n",
    "    elif item == 'neg' and -1 in sentimentFreq:\n",
    "        return sentimentFreq[-1] / len(tweets)\n",
    "    elif item == 'religious':\n",
    "        vfunc = np.vectorize(is_tweet_religious)\n",
    "        return vfunc(tweets, religionDict).sum() / len(tweets)\n",
    "    elif item == 'hatespeech' and 0 in hsolFreq:\n",
    "        return hsolFreq[0] / len(tweets)\n",
    "    elif item == 'offensive' and 1 in hsolFreq:\n",
    "        return hsolFreq[1] / len(tweets)\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     19,
     30,
     36
    ]
   },
   "outputs": [],
   "source": [
    "# Other function definitions\n",
    "# Get tweets from one user\n",
    "def getUserTweetsAndData(userTweetsFile):\n",
    "    data = []\n",
    "    tweets = []\n",
    "\n",
    "    with gzip.open(userTweetsFile,'r') as f:        \n",
    "        for tweetDeetsBinary in f:\n",
    "            # Convert each line (binary) to string\n",
    "            tweetDeetsStr = tweetDeetsBinary.decode('utf-8')\n",
    "\n",
    "            # Generate json objects\n",
    "            tweetDeetsJson = json.loads(tweetDeetsStr)\n",
    "            data.append(tweetDeetsJson)            \n",
    "            tweets.append(tweetDeetsJson[\"text\"])\n",
    "    \n",
    "    return data, tweets\n",
    "\n",
    "# Clean a tweet\n",
    "def cleanTweet(text):\n",
    "    cleanedText = \" \".join([re.sub(\"[^a-zA-Z#']\", '', x) for x in tweet_tokenizer.tokenize(text) if\n",
    "                                 x and\n",
    "                                 not x.startswith('http') and\n",
    "                                 not x.startswith('@') and\n",
    "                                 not x.startswith('#') and\n",
    "                                 x.lower() != 'rt' and\n",
    "                                 not (x.startswith('&') and x.endswith(';'))]).strip().lower()\n",
    "    return cleanedText.lower()\n",
    "\n",
    "# Clean all tweets\n",
    "def cleanAllTweets(tweets):\n",
    "    vcleanTweet = np.vectorize(cleanTweet)\n",
    "    cleanedTweets = vcleanTweet(tweets)\n",
    "    return cleanedTweets\n",
    "\n",
    "# Print error message\n",
    "def printErrorMsg(userID):\n",
    "    print(\"---------------------------------------------------------------------\")\n",
    "    print(\"Unable to calculate metrics for user:\", userID)\n",
    "    print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1,
     20,
     44,
     76,
     82
    ]
   },
   "outputs": [],
   "source": [
    "# Function definitions from \"Automated Hate Speech Detection and the Problem of Offensive Language\" paper\n",
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "def other_features(tweet):\n",
    "    \"\"\"This function takes a string and returns a list of features.\n",
    "    These include Sentiment scores, Text and Readability scores,\n",
    "    as well as Twitter specific features\"\"\"\n",
    "    sentiment = sid.polarity_scores(tweet)\n",
    "    \n",
    "    words = preprocess(tweet) #Get text only\n",
    "    \n",
    "    syllables = textstat.syllable_count(words)\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(tweet)\n",
    "    num_terms = len(tweet.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    \n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "    \n",
    "    twitter_objs = count_twitter_objs(tweet)\n",
    "    retweet = 0\n",
    "    if \"rt\" in words:\n",
    "        retweet = 1\n",
    "    features = [FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms, sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],\n",
    "                twitter_objs[2], twitter_objs[1],\n",
    "                twitter_objs[0], retweet]\n",
    "    \n",
    "    return features\n",
    "\n",
    "def get_feature_array(tweets):\n",
    "    feats=[]\n",
    "    for t in tweets:\n",
    "        feats.append(other_features(t))\n",
    "    return np.array(feats)\n",
    "\n",
    "def transform_inputs(tweets):\n",
    "    oth_array = get_feature_array(tweets)    \n",
    "    return pd.DataFrame(oth_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load training labels and dictionaries + init objs\n",
    "df = pd.read_csv(TRAIN_LABEL_FILE, dtype={'user_id': 'str'})\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "racismDict = DictFeaturizer.load(RACISM_DICT_FILE)\n",
    "racismDict.rel = False\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "hsolModel = joblib.load(open('hsof_model_mini.pkl', 'rb'))\n",
    "religionDict = ReligiousityDict(RELIGIOUS_DICTIONARY)\n",
    "religionDict.read_csv() #reads in religion dict may need to change pos for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Specify feature columns in dataframe\n",
    "featureNames = [\n",
    "    \"num_tweets\",#ok\n",
    "    \"num_followers\",#ok\n",
    "    \"day_with_most_tweets\",#ok    \n",
    "    \"flesch_kincaid_grade\",#ok\n",
    "    \"coleman_liau_index\",#ok\n",
    "    \"automated_readability_index\",#ok\n",
    "    \"linsear_write_formula\",#ok\n",
    "    \"gunning_fog\",#ok\n",
    "    \"avg_num_retweets\",#ok\n",
    "    \"avg_num_favorites\",#ok\n",
    "    \"avg_num_hashtags\",#ok\n",
    "    \"avg_num_emojis\",#ok\n",
    "    \"avg_num_links\",#ok\n",
    "    \"avg_num_linked_pics\",#ok\n",
    "    \"percent_pos_tweets\",#ok\n",
    "    \"percent_neu_tweets\",#ok\n",
    "    \"percent_neg_tweets\",#ok\n",
    "    \"avg_num_racist_words\",#ok\n",
    "    \"percent_religious_tweets\", #Austin\n",
    "    \"percent_hatespeech_tweets\",\n",
    "    \"percent_offensive_tweets\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Init/reset all fields to 0.0\n",
    "for featName in featureNames:\n",
    "    df[featName] = np.zeros(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Correct the data types in the dataframe + set df index\n",
    "df = df.astype({\"num_tweets\": int,\n",
    "                \"num_followers\": int,\n",
    "                \"num_followers\": int,\n",
    "                \"day_with_most_tweets\": int\n",
    "               })\n",
    "df = df.set_index(\"user_id\")\n",
    "#print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Calculate metrics for each user\n",
    "# Get the gzip files and load the queue\n",
    "queue = [TWEETS_DIRECTORY + objname for objname in os.listdir(TWEETS_DIRECTORY) if re.search(r\".+\\.gz$\", objname)]\n",
    "progressBar = tqdm(total=len(queue))\n",
    "\n",
    "while len(queue) > 0:\n",
    "    # Get data and tweets\n",
    "    userTweetsFile = queue.pop()\n",
    "    dataAndTweets = getUserTweetsAndData(userTweetsFile)\n",
    "    data = dataAndTweets[0]          # list of json data for each tweet\n",
    "    tweets = dataAndTweets[1]\n",
    "    totalNumTweets = len(data)\n",
    "    \n",
    "    # Skip if user has no tweets\n",
    "    if totalNumTweets == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get the user ID\n",
    "    userID = data[0][\"user\"][\"id_str\"]\n",
    "    \n",
    "    try:\n",
    "        # Clean all tweets\n",
    "        cleanedTweets = cleanAllTweets(tweets)\n",
    "\n",
    "        # Get sentiment and hatespeech/offensive language frequencies\n",
    "        sentimentFreq = getSentimentFreq(cleanedTweets, sid)\n",
    "        hsolFreq = getHsolClass(cleanedTweets, hsolModel)\n",
    "\n",
    "        df.loc[userID, \"num_tweets\"] = totalNumTweets\n",
    "        df.loc[userID, \"num_followers\"] = data[0][\"user\"][\"followers_count\"]\n",
    "        df.loc[userID, \"day_with_most_tweets\"] = getDayTweetedMost(data)\n",
    "        df.loc[userID, \"flesch_kincaid_grade\"] = getReadabilityScore('flesch', cleanedTweets)\n",
    "        df.loc[userID, \"coleman_liau_index\"] = getReadabilityScore('coleman', cleanedTweets)\n",
    "        df.loc[userID, \"automated_readability_index\"] = getReadabilityScore('automated', cleanedTweets)\n",
    "        df.loc[userID, \"linsear_write_formula\"] = getReadabilityScore('linsear', cleanedTweets)\n",
    "        df.loc[userID, \"gunning_fog\"] = getReadabilityScore('gunning', cleanedTweets)\n",
    "        df.loc[userID, \"avg_num_retweets\"] = getAvgNum('retweets', data)\n",
    "        df.loc[userID, \"avg_num_favorites\"] = getAvgNum('favorites', data)\n",
    "        df.loc[userID, \"avg_num_hashtags\"] = getAvgNum('hashtags', data)\n",
    "        df.loc[userID, \"avg_num_emojis\"] = getAvgNum('emojis', tweets)\n",
    "        df.loc[userID, \"avg_num_links\"] = getAvgNum('links', data)\n",
    "        df.loc[userID, \"avg_num_linked_pics\"] = getAvgNum('pics', data)\n",
    "        df.loc[userID, \"avg_num_racist_words\"] = getAvgNum('racist', cleanedTweets, racismDict=racismDict)\n",
    "        df.loc[userID, \"percent_pos_tweets\"] = getPercent('pos', cleanedTweets, sentimentFreq=sentimentFreq)\n",
    "        df.loc[userID, \"percent_neu_tweets\"] = getPercent('neu', cleanedTweets, sentimentFreq=sentimentFreq)\n",
    "        df.loc[userID, \"percent_neg_tweets\"] = getPercent('neg', cleanedTweets, sentimentFreq=sentimentFreq) \n",
    "        df.loc[userID, \"percent_religious_tweets\"] = getPercent('religious', cleanedTweets, religionDict=religionDict)\n",
    "        df.loc[userID, \"percent_hatespeech_tweets\"] = getPercent('hatespeech', cleanedTweets, hsolFreq=hsolFreq)\n",
    "        df.loc[userID, \"percent_offensive_tweets\"] = getPercent('offensive', cleanedTweets, hsolFreq=hsolFreq)\n",
    "        progressBar.update(1)\n",
    "\n",
    "    except:\n",
    "        printErrorMsg(userID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Clean up the dataframe\n",
    "# Drop any NaNs or nulls\n",
    "for index, row in df.iterrows():\n",
    "    if row.isnull().any():\n",
    "        df = df.drop(index)\n",
    "        \n",
    "# Normalize all values\n",
    "#df = (df - df.mean()) / (df.max() - df.min())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Output calculated metrics to a CSV file\n",
    "df.to_csv(\"../results/user_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to np array\n",
    "npDF = dfNorm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot the correlation matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for i in range(len(df.columns)):\n",
    "    print(str(i) + \": \" + df.columns[i])\n",
    "    \n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.matshow(df.corr())\n",
    "plt.xticks(range(len(df.columns)), [i for i in range(len(df.columns))])\n",
    "plt.yticks(range(len(df.columns)), [i for i in range(len(df.columns))])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr = df.corr()\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.heatmap(corr, xticklabels=[i for i in range(len(df.columns))])\n",
    "sns.heatmap(corr, yticklabels=[i for i in range(len(df.columns))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training/testing sets\n",
    "# sdo + rwa\n",
    "trainSize = int(.75*npDF.shape[0])\n",
    "Xtrain = npDF[:trainSize, 2:]\n",
    "ytrain = npDF[:trainSize, :2]\n",
    "Xtest = npDF[trainSize:, 2:]\n",
    "ytest = npDF[trainSize:, :2]\n",
    "\n",
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Run Linear Regression\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(Xtrain, ytrain)\n",
    "print(\"Score:\", regr.score(Xtest, ytest))\n",
    "yPred = regr.predict(Xtest)\n",
    "#print('Coefficients: \\n', regr.coef_)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(ytest, yPred))\n",
    "print('Variance score: %.2f' % r2_score(ytest, yPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't run past here, still broken from multiple changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Feature extraction (old)\n",
    "\"\"\"\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "tf = vectorizer.fit_transform(tweets)\n",
    "print(\"tf shape:\", tf.shape)\n",
    "\n",
    "y = np.empty(tf.shape[0])\n",
    "\n",
    "# Give each tweet the personality score of the user\n",
    "if TRAIN_LABEL_FILE == \"\":\n",
    "    # Randomly fill score if none provided\n",
    "    #y.fill(np.random.uniform(size=1)[0])\n",
    "    y = np.random.uniform(size=tf.shape[0])\n",
    "    print(y[0])\n",
    "else:\n",
    "    #y.fill(float(sdo_score))\n",
    "    y = np.random.uniform(size=tf.shape[0])\n",
    "    print(y[0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Feature selection (old)\n",
    "\"\"\"\n",
    "#tfNew = SelectKBest(f_regression, k=10).fit_transform(tf, y)\n",
    "selPercent = SelectPercentile(f_regression, percentile=10)\n",
    "tfNew = selPercent.fit_transform(tf, y)\n",
    "print(\"tfNew shape:\", tfNew.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/readability-index-pythonnlp/\n",
    "- Referenced code for calculating readability score\n",
    "- There are 4 readability formulas we can use\n",
    "    - flesch_reading_ease(text)\n",
    "    - gunning_fog(text)\n",
    "    - smog_index(text)\n",
    "    - dale_chall_readability_score(text)\n",
    "\n",
    "@article{tulkens2016automated,\n",
    "  title={The automated detection of racist discourse in dutch social media},\n",
    "  author={Tulkens, St{\\'e}phan and Hilte, Lisa and Lodewyckx, Elise and Verhoeven, Ben and Daelemans, Walter},\n",
    "  journal={Computational Linguistics in the Netherlands Journal},\n",
    "  volume={6},\n",
    "  number={1},\n",
    "  pages={3--20},\n",
    "  year={2016}\n",
    "}\n",
    "- Racism dictionary\n",
    "\n",
    "https://stackoverflow.com/questions/43146528/how-to-extract-all-the-emojis-from-text\n",
    "- Code used to extract emojis\n",
    "\n",
    "@inproceedings{hateoffensive,\n",
    "  title = {Automated Hate Speech Detection and the Problem of Offensive Language},\n",
    "  author = {Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar}, \n",
    "  booktitle = {Proceedings of the 11th International AAAI Conference on Web and Social Media},\n",
    "  series = {ICWSM '17},\n",
    "  year = {2017},\n",
    "  location = {Montreal, Canada},\n",
    "  pages = {512-515}\n",
    "  }\n",
    "  - Hate-speech and offensive language classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
